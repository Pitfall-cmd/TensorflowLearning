{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.gfile as gfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "NUMBER = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "LOWERCASE = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u',\n",
    "            'v', 'w', 'x', 'y', 'z']\n",
    "UPPERCASE = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U',\n",
    "           'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "CAPTCHA_CHARSET = NUMBER   # 验证码字符集\n",
    "CAPTCHA_LEN = 4            # 验证码长度\n",
    "CAPTCHA_HEIGHT = 60        # 验证码高度\n",
    "CAPTCHA_WIDTH = 160        # 验证码宽度\n",
    "\n",
    "TRAIN_DATA_DIR = './train_data/' # 验证码数据集目录\n",
    "TEST_DATA_DIR = './test-data/'\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 10\n",
    "OPT = 'adam'\n",
    "LOSS = 'binary_crossentropy'\n",
    "\n",
    "MODEL_DIR = './model/train_demo/'\n",
    "MODEL_FORMAT = '.h5'\n",
    "HISTORY_DIR = './history/train_demo/'\n",
    "HISTORY_FORMAT = '.history'\n",
    "filename_str = \"{}captcha_{}_{}_bs_{}_epochs_{}{}\"\n",
    "# 模型网络结构文件\n",
    "MODEL_VIS_FILE = 'captcha_classfication' + '.png'\n",
    "# 模型文件\n",
    "MODEL_FILE = filename_str.format(MODEL_DIR, OPT, LOSS, str(BATCH_SIZE), str(EPOCHS), MODEL_FORMAT)\n",
    "# 训练记录文件\n",
    "HISTORY_FILE = filename_str.format(HISTORY_DIR, OPT, LOSS, str(BATCH_SIZE), str(EPOCHS), HISTORY_FORMAT)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def rgb2gray(img):\n",
    "    # Y' = 0.299 R + 0.587 G + 0.114 B\n",
    "    # https://en.wikipedia.org/wiki/Grayscale#Converting_color_to_grayscale\n",
    "    return np.dot(img[...,:3], [0.299, 0.587, 0.114])\n",
    "def text2vec(text, length=CAPTCHA_LEN, charset=CAPTCHA_CHARSET):\n",
    "    text_len = len(text)\n",
    "    # 验证码长度校验\n",
    "    if text_len != length:\n",
    "        raise ValueError('Error: length of captcha should be {}, but got {}'.format(length, text_len))\n",
    "\n",
    "    # 生成一个形如（CAPTCHA_LEN*CAPTHA_CHARSET,) 的一维向量\n",
    "    # 例如，4个纯数字的验证码生成形如(4*10,)的一维向量\n",
    "    vec = np.zeros(length * len(charset))\n",
    "    for i in range(length):\n",
    "        # One-hot 编码验证码中的每个数字\n",
    "        # 每个字符的热码 = 索引 + 偏移量\n",
    "        vec[charset.index(text[i]) + i*len(charset)] = 1\n",
    "    return vec\n",
    "def vec2text(vector):\n",
    "    if not isinstance(vector, np.ndarray):\n",
    "        vector = np.asarray(vector)\n",
    "    vector = np.reshape(vector, [CAPTCHA_LEN, -1])\n",
    "    text = ''\n",
    "    for item in vector:\n",
    "        text += CAPTCHA_CHARSET[np.argmax(item)]\n",
    "    return text\n",
    "\n",
    "def fit_keras_channels(batch, rows=CAPTCHA_HEIGHT, cols=CAPTCHA_WIDTH):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        batch = batch.reshape(batch.shape[0], 1, rows, cols)\n",
    "        input_shape = (1, rows, cols)\n",
    "    else:\n",
    "        batch = batch.reshape(batch.shape[0], rows, cols, 1)\n",
    "        input_shape = (rows, cols, 1)\n",
    "\n",
    "    return batch, input_shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3957, 60, 160, 1) <class 'numpy.ndarray'>\n",
      "(60, 160, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "for filename in glob.glob(TRAIN_DATA_DIR + '*.png'):\n",
    "    X_train.append(np.array(Image.open(filename)))\n",
    "    Y_train.append(filename.lstrip(TRAIN_DATA_DIR+'\\\\').rstrip('.png'))\n",
    "\n",
    "# list -> rgb(numpy)\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "# rgb -> gray\n",
    "X_train = rgb2gray(X_train)\n",
    "# normalize\n",
    "X_train = X_train / 255\n",
    "# Fit keras channels\n",
    "X_train, input_shape = fit_keras_channels(X_train)\n",
    "\n",
    "print(X_train.shape, type(X_train))\n",
    "print(input_shape)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3957, 40) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "Y_train = list(Y_train)\n",
    "\n",
    "for i in range(len(Y_train)):\n",
    "    Y_train[i] = text2vec(Y_train[i])\n",
    "\n",
    "Y_train = np.asarray(Y_train)\n",
    "\n",
    "print(Y_train.shape, type(Y_train))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(940, 60, 160, 1) <class 'numpy.ndarray'>\n",
      "(940, 40) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "for filename in glob.glob(TEST_DATA_DIR + '*.png'):\n",
    "    X_test.append(np.array(Image.open(filename)))\n",
    "    Y_test.append(filename.lstrip(TEST_DATA_DIR+'\\\\').rstrip('.png'))\n",
    "\n",
    "# list -> rgb -> gray -> normalization -> fit keras\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "X_test = rgb2gray(X_test)\n",
    "X_test = X_test / 255\n",
    "X_test, _ = fit_keras_channels(X_test)\n",
    "\n",
    "Y_test = list(Y_test)\n",
    "for i in range(len(Y_test)):\n",
    "    Y_test[i] = text2vec(Y_test[i])\n",
    "\n",
    "Y_test = np.asarray(Y_test)\n",
    "\n",
    "print(X_test.shape, type(X_test))\n",
    "print(Y_test.shape, type(Y_test))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "#输入层\n",
    "inputs=Input(shape=input_shape,name='inputs')\n",
    "\n",
    "conv1=Conv2D(32,(3,3),name='conv1',activation='relu')(inputs)\n",
    "\n",
    "conv2=Conv2D(32,(3,3),name='conv2',activation='relu')(conv1)\n",
    "\n",
    "pool2=MaxPool2D(pool_size=(2,2),padding='same',name=\"pool\")(conv2)\n",
    "# 第3层卷积\n",
    "conv3 = Conv2D(64, (3, 3), name = \"conv3\")(pool2)\n",
    "relu3 = Activation('relu', name=\"relu3\")(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2,2), padding='same', name=\"pool3\")(relu3)\n",
    "\n",
    "# 将 Pooled feature map 摊平后输入全连接网络\n",
    "x = Flatten()(pool3)\n",
    "\n",
    "# Dropout\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "# 4个全连接层分别做10分类，分别对应4个字符。\n",
    "x = [Dense(10, activation='softmax', name='fc%d'%(i+1))(x) for i in range(4)]\n",
    "\n",
    "# 4个字符向量拼接在一起，与标签向量形式一致，作为模型输出。\n",
    "outs = Concatenate()(x)\n",
    "\n",
    "model=Model(inputs=inputs,outputs=outs)\n",
    "model.compile(optimizer=OPT,loss=LOSS,metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 60, 160, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 58, 158, 32)  320         inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 56, 156, 32)  9248        conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool (MaxPooling2D)             (None, 28, 78, 32)   0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 26, 76, 64)   18496       pool[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "relu3 (Activation)              (None, 26, 76, 64)   0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 13, 38, 64)   0           relu3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 31616)        0           pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 31616)        0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 10)           316170      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc2 (Dense)                     (None, 10)           316170      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc3 (Dense)                     (None, 10)           316170      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc4 (Dense)                     (None, 10)           316170      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 40)           0           fc1[0][0]                        \n",
      "                                                                 fc2[0][0]                        \n",
      "                                                                 fc3[0][0]                        \n",
      "                                                                 fc4[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 1,292,744\n",
      "Trainable params: 1,292,744\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 3957 samples, validate on 940 samples\n",
      "Epoch 1/10\n",
      " - 99s - loss: 0.3259 - acc: 0.9000 - val_loss: 0.3250 - val_acc: 0.9000\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-21-e4da989adcd2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m                     \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mEPOCHS\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m                     \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m                     validation_data=(X_test, Y_test))\n\u001B[0m",
      "\u001B[1;32mD:\\Anoconda2\\envs\\Tensorflow2021\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001B[0m\n\u001B[0;32m   1037\u001B[0m                                         \u001B[0minitial_epoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minitial_epoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1038\u001B[0m                                         \u001B[0msteps_per_epoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msteps_per_epoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1039\u001B[1;33m                                         validation_steps=validation_steps)\n\u001B[0m\u001B[0;32m   1040\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1041\u001B[0m     def evaluate(self, x=None, y=None,\n",
      "\u001B[1;32mD:\\Anoconda2\\envs\\Tensorflow2021\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001B[0m in \u001B[0;36mfit_loop\u001B[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001B[0m\n\u001B[0;32m    197\u001B[0m                     \u001B[0mins_batch\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mins_batch\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtoarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 199\u001B[1;33m                 \u001B[0mouts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mins_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    200\u001B[0m                 \u001B[0mouts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mto_list\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mouts\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    201\u001B[0m                 \u001B[1;32mfor\u001B[0m \u001B[0ml\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mo\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout_labels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mouts\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anoconda2\\envs\\Tensorflow2021\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m   2713\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_legacy_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2714\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2715\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2716\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2717\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mpy_any\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mis_tensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anoconda2\\envs\\Tensorflow2021\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m   2673\u001B[0m             \u001B[0mfetched\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_callable_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0marray_vals\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrun_metadata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_metadata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2674\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2675\u001B[1;33m             \u001B[0mfetched\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_callable_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0marray_vals\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2676\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mfetched\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2677\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anoconda2\\envs\\Tensorflow2021\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1437\u001B[0m           ret = tf_session.TF_SessionRunCallable(\n\u001B[0;32m   1438\u001B[0m               \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_session\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_session\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_handle\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstatus\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1439\u001B[1;33m               run_metadata_ptr)\n\u001B[0m\u001B[0;32m   1440\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mrun_metadata\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1441\u001B[0m           \u001B[0mproto_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf_session\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTF_GetBuffer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrun_metadata_ptr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "## 模型可视化\n",
    "#plot_model(model, to_file=MODEL_VIS_FILE, show_shapes=True)\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_test, Y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(vec2text(Y_test[9]))\n",
    "yy = model.predict(X_test[9].reshape(1, 60, 160, 1))\n",
    "print(vec2text(yy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#保存模型\n",
    "if not gfile.Exists(MODEL_FILE):\n",
    "    gfile.MakeDirs(MODEL_FILE)\n",
    "model.save(MODEL_FILE)\n",
    "print('Saved trained model at %s ' % MODEL_FILE)\n",
    "#保存训练过程记录\n",
    "\n",
    "history.history['acc']\n",
    "history.history.keys()\n",
    "if gfile.Exists(HISTORY_DIR) == False:\n",
    "    gfile.MakeDirs(HISTORY_DIR)\n",
    "\n",
    "with open(HISTORY_FILE, 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(HISTORY_FILE)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}